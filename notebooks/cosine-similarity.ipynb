{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36467c2a",
   "metadata": {},
   "source": [
    "# TEXT SUMMERIZATION - COSINE ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667a194e",
   "metadata": {},
   "source": [
    "**1. Preprocessing the texts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7cce541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install matplotlib\n",
    "# pip install wordcloud\n",
    "# pip install spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3552701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download(\"punkt\")  # for tokenization\n",
    "#nltk.download(\"stopwords\")  # for stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e4f8d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # regular expressions\n",
    "import nltk # natural language toolkit\n",
    "import string # for string operations\n",
    "import numpy as np # numerical python\n",
    "import networkx as nx # networkx for graph operations\n",
    "from nltk.cluster.util import cosine_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c9fee61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial intelligence is human like intelligence machines. It is the study of intelligent artificial agents. Science and engineering to produce intelligent machines. Solve problems and have intelligence. Related to intelligent behavior machines. Developing of reasoning machines. Learn from mistakes and successes. Artificial intelligence is related to reasoning in everyday situations.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_text = \"\"\"Artificial intelligence is human like intelligence machines.\n",
    "                   It is the study of intelligent artificial agents.\n",
    "                   Science and engineering to produce intelligent machines.\n",
    "                   Solve problems and have intelligence.\n",
    "                   Related to intelligent behavior machines.\n",
    "                   Developing of reasoning machines.\n",
    "                   Learn from mistakes and successes.\n",
    "                   Artificial intelligence is related to reasoning in everyday situations.\"\"\"\n",
    "original_text = re.sub(r'\\s+', ' ', original_text)  # remove extra spaces and newlines\n",
    "original_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce6a9b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')  # get the list of stopwords in English\n",
    "print(stopwords)\n",
    "len(stopwords)  # number of stopwords\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b135890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text): \n",
    "    formatted_text = text.lower()\n",
    "    tokens = []\n",
    "    # tokenize the text using word tokenizer \n",
    "    for token in nltk.word_tokenize(formatted_text, language=\"english\", preserve_line=False): \n",
    "        tokens.append(token)\n",
    "    #print(tokens)\n",
    "    tokens = [word for word in tokens if word not in stopwords and word not in string.punctuation] # remove stopwords and punctuation from the text \n",
    "    formatted_text = \" \".join(element for element in tokens)  # join the tokens back to string\n",
    "    \n",
    "    return formatted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151b2c83",
   "metadata": {},
   "source": [
    "**2. Function to calculate similarity between sentences**\n",
    "\n",
    "- Link: https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "- Step by step calculations: https://janav.wordpress.com/2013/10/27/tf-idf-and-cosine-similarity/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d375717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial intelligence is human like intelligence machines.',\n",
       " 'It is the study of intelligent artificial agents.',\n",
       " 'Science and engineering to produce intelligent machines.',\n",
       " 'Solve problems and have intelligence.',\n",
       " 'Related to intelligent behavior machines.',\n",
       " 'Developing of reasoning machines.',\n",
       " 'Learn from mistakes and successes.',\n",
       " 'Artificial intelligence is related to reasoning in everyday situations.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_sentences = [sentence for sentence in nltk.sent_tokenize(original_text)]\n",
    "original_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b84208e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artificial intelligence human like intelligence machines',\n",
       " 'study intelligent artificial agents',\n",
       " 'science engineering produce intelligent machines',\n",
       " 'solve problems intelligence',\n",
       " 'related intelligent behavior machines',\n",
       " 'developing reasoning machines',\n",
       " 'learn mistakes successes',\n",
       " 'artificial intelligence related reasoning everyday situations']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_sentences = [preprocess(original_sentence) for original_sentence in original_sentences]\n",
    "formatted_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9ef6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentence_similarity(sent1, sent2): # return a number how similar two sentences are\n",
    "    word1 = [word for word in nltk.word_tokenize(sent1)]\n",
    "    word2 = [word for word in nltk.word_tokenize(sent2)]\n",
    "    # print(word1)\n",
    "    # print(word2)\n",
    "    \n",
    "    all_words = list(set(word1 + word2)) # create a set of all words in both sentences and remove duplicates\n",
    "    print(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f9adac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artificial', 'human', 'intelligent', 'agents', 'machines', 'like', 'study', 'intelligence']\n"
     ]
    }
   ],
   "source": [
    "calculate_sentence_similarity(formatted_sentences[0], formatted_sentences[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca22aa",
   "metadata": {},
   "source": [
    "**3. Function to create the similarity**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e38b26",
   "metadata": {},
   "source": [
    "**4. Function to summarize the text**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4351c281",
   "metadata": {},
   "source": [
    "**5. Evaluation**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
