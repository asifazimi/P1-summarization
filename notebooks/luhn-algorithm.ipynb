{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "213d22ed",
   "metadata": {},
   "source": [
    "# TEXT SUMMERIZATION - LUHN ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1492c5e4",
   "metadata": {},
   "source": [
    "**1. Preprocessing the texts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "583f8931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # regular expressions\n",
    "import nltk # natural language toolkit\n",
    "import string # for string operations\n",
    "import heapq # for finding n largest elements\n",
    "from IPython.core.display import HTML # for displaying HTML in Jupyter Notebook\n",
    "from goose3 import Goose # for extracting text from web pages\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ec369d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text = \"\"\"Artificial intelligence is human like intelligence machines.\n",
    "                   It is the study of intelligent artificial agents.\n",
    "                   Science and engineering to produce intelligent machines.\n",
    "                   Solve problems and have intelligence.\n",
    "                   Related to intelligent behavior machines.\n",
    "                   Developing of reasoning machines.\n",
    "                   Learn from mistakes and successes.\n",
    "                   Artificial intelligence is related to reasoning in everyday situations.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4602db19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial intelligence is human like intelligence. It is the study of intelligent artificial agents. Science and engineering to produce intelligent machines. Solve problems and have intelligence. Related to intelligent behavior. Developing of reasoning machines. Learn from mistakes and successes. Artificial intelligence is related to reasoning in everyday situations.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_text = re.sub(r'\\s+', ' ', original_text)  # remove extra spaces and newlines\n",
    "original_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0403d482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')  # get the list of stopwords in English\n",
    "print(stopwords)\n",
    "len(stopwords)  # number of stopwords\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd22ffe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text): \n",
    "    formatted_text = text.lower()\n",
    "    tokens = []\n",
    "    # tokenize the text using word tokenizer \n",
    "    for token in nltk.word_tokenize(formatted_text, language=\"english\", preserve_line=False): \n",
    "        tokens.append(token)\n",
    "    #print(tokens)\n",
    "    tokens = [word for word in tokens if word not in stopwords and word not in string.punctuation] # remove stopwords and punctuation from the text \n",
    "    formatted_text = \" \".join(element for element in tokens)  # join the tokens back to string\n",
    "    \n",
    "    return formatted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e619a55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'artificial intelligence human like intelligence study intelligent artificial agents science engineering produce intelligent machines solve problems intelligence related intelligent behavior developing reasoning machines learn mistakes successes artificial intelligence related reasoning everyday situations'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_text = preprocess(original_text)\n",
    "formatted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc680ad",
   "metadata": {},
   "source": [
    "**2. Function to calculate sentences score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c067a6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentences_score(sentences, important_words, distance): \n",
    "    scores = []\n",
    "    sentence_index = 0\n",
    "    \n",
    "    for sentence in [nltk.word_tokenize(sentence) for sentence in sentences]: # tokenize each sentence\n",
    "        # print(\"---------\")\n",
    "        # print(\"Words in each Sentence: \", sentence)\n",
    "        \n",
    "        word_index = []\n",
    "        for word in important_words: \n",
    "            # print(\"Important word: \", word)\n",
    "            try: \n",
    "                word_index.append(sentence.index(word))\n",
    "            except ValueError:\n",
    "                pass \n",
    "        word_index.sort()\n",
    "        # print(\"Word Indexes: \", word_index) # indexes of important words in the sentence\n",
    "        \n",
    "        if len(word_index) == 0:\n",
    "            continue\n",
    "        \n",
    "        # [0, 1, 2, 5, 8, 9]\n",
    "        group_list = [] # list of groups of important words\n",
    "        group = [word_index[0]] # current group of important words\n",
    "        \n",
    "        i = 1 # 3\n",
    "        while i < len(word_index): # 3\n",
    "            # first execution: 1 - 0\n",
    "            # second execution: 2 - 1\n",
    "            # third execution: 5 - 2\n",
    "            if word_index[i] - word_index[i-1] < distance: \n",
    "                group.append(word_index[i])\n",
    "                # print(\"Group after append: \", group)\n",
    "            else: \n",
    "                group_list.append(group[:])\n",
    "                group = [word_index[i]]\n",
    "                # print(\"New Group: \", group)\n",
    "            i += 1\n",
    "            \n",
    "        group_list.append(group) # append the last group\n",
    "        # print(\"Group List: \", group_list)\n",
    "            \n",
    "        # calculate the score for each group\n",
    "        max_group_score = 0\n",
    "        for g in group_list: \n",
    "            # print(g)\n",
    "            important_words_in_group = len(g)\n",
    "            total_words_in_group = g[-1] - g[0] + 1 # total words in the group  \n",
    "            score = 1.0 * (important_words_in_group ** 2) / total_words_in_group # multiplied by one in order to have the value in the same scale \n",
    "            # print(\"Score: \", score)\n",
    "            \n",
    "            if score > max_group_score:\n",
    "                max_group_score = score\n",
    "            \n",
    "        scores.append((max_group_score, sentence_index))\n",
    "        sentence_index += 1\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c10e46",
   "metadata": {},
   "source": [
    "**6. Function to summarize the texts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7b002ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text, top_n_words, distance, number_of_sentences):\n",
    "    original_setences = [sentence for sentence in nltk.sent_tokenize(text)] # tokenize the text into sentences\n",
    "    # print(\"Before Preprocessing text: \", original_setences)\n",
    "    formatted_sentences = [preprocess(original_sentence) for original_sentence in original_setences] # preprocess each sentence\n",
    "    # print(\"After Preprocessing text: \", formatted_sentences)\n",
    "    words = [word for sentence in formatted_sentences for word in nltk.word_tokenize(sentence)] # tokenize the preprocessed sentences into words\n",
    "    # print(\"Tokenized words: \", words)\n",
    "    frequency = nltk.FreqDist(words) # get the frequency distribution of the words\n",
    "    # return frequency\n",
    "    top_n_words = [word[0] for word in frequency.most_common(top_n_words)] # get the top n words\n",
    "    # print(\"Top n words: \", top_n_words)\n",
    "    sentences_score = calculate_sentences_score(formatted_sentences, top_n_words, distance)\n",
    "    # print(\"Score in each sentence (score, sentence_index): \", sentences_score)\n",
    "    best_sentences = heapq.nlargest(number_of_sentences, sentences_score)\n",
    "    # print(\"Best sentences (score, sentence_index): \", best_sentences)\n",
    "    best_sentences = [original_setences[i] for (score, i) in best_sentences]\n",
    "    # print(best_sentences)\n",
    "    return original_setences, best_sentences, sentences_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dedc6036",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_setences, best_sentences, sentences_score = summarize(original_text, 5, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "39d7a03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Summary</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "  Artificial intelligence is human like intelligence machines. It is the study of intelligent artificial agents.<mark>Science and engineering to produce intelligent machines.</mark> Solve problems and have intelligence.<mark>Related to intelligent behavior machines.</mark> Developing of reasoning machines.<mark>Learn from mistakes and successes.</mark> Artificial intelligence is related to reasoning in everyday situations."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \" \"\n",
    "display(HTML(f\"<h2>Summary</h2>\"))\n",
    "for sentence in original_setences:\n",
    "    if sentence in best_sentences: \n",
    "        text += sentence.replace(sentence, f\"<mark>{sentence}</mark>\")\n",
    "    else: \n",
    "        text += \" \" + sentence\n",
    "display(HTML(f\"\"\"{text}\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e870a351",
   "metadata": {},
   "source": [
    "**9. Evaluation**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
